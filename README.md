# **Sensor Haptic Guitar with Quantum Probabilistic Data Analysis**
</br>

## **Project Overview**
This project explores a novel interactive music system that fuses wearable sensor-based instrumentation (using a midi interface) with quantum and algorithm inspired data processing. The central aim is to investigate how probabilistic quantum ouputs driven by user gestures can shape generative music and offer insight into the edge between structured harmony and controlled chaos. 
</br>

## **Background & Intuitive Ideas**

### Real-time Musical Interaction
(*Can I use the input from the client to give recommendations of possible songs that might sound good?*)
<br>
- Users play a **virtual guitar** instrument using a wearable sensor system (finger rings and wrist-mounted ToF sensors).
- Inputs (strums, finger positions) are converted to MIDI signals and timestamped for **data logging**.
- These sensor values guide algorithmic recommendations of **musically viable follow-ups** based on classical **music theory rules** (chord progressions, scale compatibility, rhythmic flow).

### Data Analysis and Quantum
( *What does "quantum logic" sound like? Can we hear the "texture" of quantum unpredictability?*)
</br>
- Introduces **Qiskit-based quantum circuits**, where classical input biases gate rotations or entanglements.
- Measurement results from these circuits introduce **probabilistic variation** into:
  - Chord choice
  - Rhythm pattern
  - Timbre modulation
    
### Visualization and Human Expression
(*Can we showcase in an easy way for people to digest? Humanize the idea of quantum slightly or find a way this project might help people understand?*)
> Think of it as a duet between player and improviser.
</br>
- **Interactive**: Real-time feedback from gestures + visualizations.
- **Affordable**: DIY electronics using ESP32, sensors, and open-source code.
- **Educational**: Makes quantum ideas tangible through audio-visual feedback.
